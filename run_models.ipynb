{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sleep_classif.CNNmultitaper import ConvNetMultitaper\n",
    "from sleep_classif.LSTMConv import LSTM_Conv\n",
    "from sleep_classif.CNNadvanced import CNN_Advanced\n",
    "from sleep_classif.CNNmodel import SimpleCNN\n",
    "\n",
    "# import loaders and other functions\n",
    "from sleep_classif.preprocessing import compute_tapers\n",
    "from sleep_classif.dataloaders import MultiTaperSet, RawDataSet, FFT_Raw_DataSet\n",
    "from sleep_classif.trainer import Trainer\n",
    "\n",
    "# import from other librairies \n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train basic CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "data_path_test = './data/raw_data/X_test.h5'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "raw_train_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)\n",
    "\n",
    "raw_test_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_test,\n",
    "                                 target_path = target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "# split train and validation set\n",
    "data_set = raw_train_set\n",
    "train_len = int(len(data_set)*train_ratio)\n",
    "train_set, validation_set = torch.utils.data.random_split(data_set, [train_len, len(data_set) - train_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(simple_cnn.parameters())\n",
    "trainer = Trainer(simple_cnn,\n",
    "                  nn.CrossEntropyLoss(),\n",
    "                  optimizer,\n",
    "                  trainloader,\n",
    "                  device,\n",
    "                  valid_data_loader = validationloader,\n",
    "                  class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(0, 25):\n",
    "    loss, accuracy = trainer.train_epoch()\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN + Multitaper Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MultiTapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_tapers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eeg_path_train = './data/pre_processed_data/Multitaper_eeg_train.npy'\n",
    "features_eeg_path_test = './data/pre_processed_data/Multitaper_eeg_test.npy'\n",
    "\n",
    "features_position_path_train = './data/pre_processed_data/Multitaper_position_train.npy'\n",
    "features_position_path_test = './data/pre_processed_data/Multitaper_position_test.npy'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "taper_train_set = MultiTaperSet(device=device,\n",
    "                                features_eeg_path = features_eeg_path_train,\n",
    "                                features_position_path = features_position_path_train,\n",
    "                                target_path = target_path)\n",
    "\n",
    "taper_test_set = MultiTaperSet(device=device,\n",
    "                                features_eeg_path = features_eeg_path_test,\n",
    "                                features_position_path = features_position_path_test,\n",
    "                                target_path = target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "# split train and validation set\n",
    "data_set = taper_train_set\n",
    "train_len = int(len(data_set)*train_ratio)\n",
    "train_set, validation_set = torch.utils.data.random_split(data_set, [train_len, len(data_set) - train_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=len(validation_set), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_taper_model = ConvNetMultitaper().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(CNN_taper_model.parameters())\n",
    "trainer = Trainer(CNN_taper_model,\n",
    "                  nn.CrossEntropyLoss(),\n",
    "                  optimizer,\n",
    "                  trainloader,\n",
    "                  device,\n",
    "                  valid_data_loader = validationloader,\n",
    "                  class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(0, 25):\n",
    "    loss, accuracy = trainer.train_epoch()\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an advanced CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "data_path_test = './data/raw_data/X_test.h5'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "\n",
    "\n",
    "raw_train_set = FFT_Raw_DataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)\n",
    "\n",
    "raw_test_set = FFT_Raw_DataSet(device=device,\n",
    "                                 data_path = data_path_test,\n",
    "                                 target_path = target_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "# split train and validation set\n",
    "data_set = raw_train_set\n",
    "train_len = int(len(data_set)*train_ratio)\n",
    "train_set, validation_set = torch.utils.data.random_split(data_set, [train_len, len(data_set) - train_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=len(validation_set), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_feat, fft_feat, raw_pos_feat, fft_pos_feat = raw_train_set.feature_shape()\n",
    "num_classes = 5\n",
    "raw_feat, fft_feat, raw_pos_feat, fft_pos_feat = 5,5,3,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_Advanced_model = CNN_Advanced(raw_feat, fft_feat, raw_pos_feat, fft_pos_feat, num_classes, 0.5).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(CNN_Advanced_model.parameters())\n",
    "trainer = Trainer(CNN_Advanced_model,\n",
    "                  nn.CrossEntropyLoss(),\n",
    "                  optimizer,\n",
    "                  trainloader,\n",
    "                  device,\n",
    "                  valid_data_loader = validationloader,\n",
    "                  class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(0, 25):\n",
    "    loss, accuracy = trainer.train_epoch()\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_taper_model = ConvNetMultitaper().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitaper_train_set = MultiTaperSet(device = device)\n",
    "multitaper_test_set = MultiTaperSet(device=device, features_eeg_path = './data/pre_processed_data/Multitaper_eeg_test.npy', features_position_path = './data/pre_processed_data/Multitaper_position_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "# split train and validation set\n",
    "data_set = multitaper_train_set\n",
    "train_len = int(len(data_set)*train_ratio)\n",
    "train_set, validation_set = torch.utils.data.random_split(data_set, [train_len, len(data_set) - train_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=len(validation_set), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(CNN_taper_model.parameters())\n",
    "trainer = Trainer(CNN_taper_model,\n",
    "                 nn.CrossEntropyLoss(),\n",
    "                 optimizer,trainloader,\n",
    "                 device,\n",
    "                 valid_data_loader = validationloader,\n",
    "                 class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727])\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(0, 25):\n",
    "    loss, accuracy = trainer.train_epoch()\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "data_path_test = './data/raw_data/X_test.h5'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "\n",
    "\n",
    "raw_train_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)\n",
    "\n",
    "raw_test_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_test,\n",
    "                                 target_path = target_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "# split train and validation set\n",
    "data_set = raw_train_set\n",
    "train_len = int(len(data_set)*train_ratio)\n",
    "train_set, validation_set = torch.utils.data.random_split(data_set, [train_len, len(data_set) - train_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=len(validation_set), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feat = raw_train_set.feature_shape()\n",
    "num_classes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Conv_model = LSTM_Conv(raw_feat, num_classes)\n",
    "LSTM_Conv_model = LSTM_Conv_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(LSTM_Conv_model.parameters())\n",
    "\n",
    "trainer = Trainer(LSTM_Conv_model,\n",
    "                  nn.CrossEntropyLoss(),\n",
    "                  optimizer,\n",
    "                  trainloader,\n",
    "                  device,\n",
    "                  valid_data_loader = validationloader,\n",
    "                  class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]), \n",
    "                  requires_softmax = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(0, 25):\n",
    "    loss, accuracy = trainer.train_epoch()\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-python38-py",
   "name": "common-cu110.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m87"
  },
  "interpreter": {
   "hash": "90400e2509a7f97e1574e9e217fc898b753a8c591c8f81400b72bc0569fd4fc5"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
